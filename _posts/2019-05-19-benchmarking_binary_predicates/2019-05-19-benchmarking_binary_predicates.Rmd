---
title: "Benchmarking binary predicates"
author: "Nils Ratnaweera"
date: "2019-05-19T11:00:00+01:00"
categories: ["R"]
tags: ["GIS", "sf","benchmarking","R"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

```


## TL;DR

Say you want to find out whether some spatial points lie in a polygon or not (for example, if you want to filter all train stations located within a state). When using the package `sf` in `R`, several function can lead you to the same result. You can use: `st_within`, `st_contains`, `st_intersects` or `st_covered_by`, and if your dataset is large, speed matters. I wanted to test which function is the fastest and as it turns out, `st_contains` is the clear winner.


## The Premise

I had recently needed to filter some 30k Points based on whether they were within a certain polygon or not. It looked something like this:
```{r, warning=FALSE,message=FALSE}

library(sf)
library(tidyverse)


# I obtained this data from swisstopo https://www.swisstopo.admin.ch/en/geodata/landscape/boundaries3d.html and stored it on my local hard drive as a geopackage. 
# liechtenstein <- sf::read_sf("Geodata/vector/swissBOUNDARIES3D/swissboundaries3d_2021-07.gpkg", query = "SELECT * FROM TLM_LANDESGEBIET WHERE NAME = 'Liechtenstein'")
# st_write(liechtenstein, "liechtenstein.gpkg")

liechtenstein <- st_read("liechtenstein.gpkg")


points <- st_bbox(liechtenstein) %>% 
  st_as_sfc() %>%
  st_buffer(1000) %>%
  st_sample(1000)

ggplot(data = points) + 
  geom_sf()+
  geom_sf(data = liechtenstein,fill = "red",alpha = 0.3) + 
  theme_void()


```

My first approach was to use `st_within()` from my favourite `R` package `sf`, but I had to abort the process before it was finished since it took too long. There was not much I could do to optimize the code, so I had to look for alternatives. "_Is the point *within* the polygon?_" can also be rephrased to "_Does the polygon *contain* this point?_" (using `st_contains`) and in my case, `st_intersects` and `st_covered_by` do the job as well. 

(Note: `st_intersects` is slightly different to `st_within` / `st_contains` / `st_covered_by`, especially when points are precisely on the line. Also note that dimensions of the resulting matrix vary depending on which operation is used.)


```{r}
points_filter1 <- points[st_within(points,liechtenstein,sparse = FALSE)[,1]]
points_filter2 <- points[st_contains(liechtenstein,points,sparse = FALSE)[1,]]
points_filter3 <- points[st_intersects(points,liechtenstein,sparse = FALSE)[,1]]
points_filter4 <- points[st_covered_by(points,liechtenstein,sparse = FALSE)[,1]]

ggplot()  + 
  geom_sf(data = liechtenstein) + 
  geom_sf(data = points_filter1) + theme_void()

identical(points_filter1,points_filter2)
identical(points_filter1,points_filter3)
identical(points_filter1,points_filter4)

```


## Benchmarking the functions

To find out which function does the job fastest, I decided to benchmark all functions with `microbenchmark`. Since it doesn't always take the same amount of time to process the same function, it makes sense to run each function multiple times (`times = 100`).


```{r}

library(microbenchmark)
library(ggridges)

mbm  <- microbenchmark(
  intersects = st_intersects(liechtenstein,points),
  within = st_within(points,liechtenstein),
  contains = st_contains(liechtenstein,points),
  covered_by = st_covered_by(points,liechtenstein),
  times = 100
)

mbm$time <- microbenchmark:::convert_to_unit(mbm$time,"t")

mbm %>%
  mutate(
    expr = fct_reorder(expr,time,median,.desc = TRUE)
  ) %>%
  ggplot(aes(time,expr,fill = ..x..)) +
  geom_density_ridges_gradient(scale = 2, rel_min_height = 0.01) +
  scale_fill_viridis_c(option = "C")  +
  labs(y = "Function",x = paste0("Duration (in ",attr(mbm$time,"unit"),")")) +
  theme_minimal() +
  theme(legend.position="none")

```

What we can see in the plot above, is that `st_within` and `st_covered_by` are similar in speed and the slowest of the four functions.

## Scalability: Raising the number of points

I ran the function with a thousand points, but but my real life problem had 30'000. So the question is: How do the functions scale? Some functions are better on larger datasets than on smaller ones. So I'll test this by raising the number of points in `point`.


```{r}
mbm2 <- map_dfr(c(5e3,10e3,20e3),function(n_points){
  
  points <- st_sample(st_buffer(liechtenstein,1000),n_points,what = "centers")

  mbm  <- microbenchmark(
  intersects = st_intersects(liechtenstein,points),
  within = st_within(points,liechtenstein),
  contains = st_contains(liechtenstein,points),
  covered_by = st_covered_by(points,liechtenstein),
  times = 10
  )
  as.data.frame(mbm) %>%
    mutate(n = n_points)
})
```


Apparently, `st_contains` is still the fastest function of all four, as you can see in the plot below. So the take home message for me: use `st_contains` when you can!

```{r}

mbm2$time <- microbenchmark:::convert_to_unit(mbm2$time,"t")



mbm2 %>%
  mutate(
    n = fct_reorder(formatC(n,big.mark = "'",format = "fg"),n),
    expr = fct_reorder(expr,time,median,.desc = TRUE)
    ) %>%
  ggplot(aes(time,expr,fill = n)) +
  geom_density_ridges_gradient(rel_min_height = 0.01) +
  scale_fill_manual(name = "Number of points", values = RColorBrewer::brewer.pal(3, "YlOrRd")) +
  labs(y = "Function",x = paste0("Duration (in ",attr(mbm$time,"unit"),")")) +
  theme_minimal() +
  theme(legend.position = "bottom")
  
```